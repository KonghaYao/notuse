<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->

# JSpider 课前
基础爬虫知识

---

<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->

### 为什么会有爬虫？

- 随着互联网的信息资源越来越多，很多的数据被放置在网络上。

- 这些信息被包裹在网页之中，人力批量获取很难。

- 所以**使用代码进行网页浏览并进行信息收集的现象** 就出现了，这些代码被称为 **“爬虫”**。

- - -

<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->

- 随着信息收集的自动化需求越来越高，需要通过软件来实现**自动爬取，分析，检索信息**，这一类软件被称为 **“搜索引擎”** 。

- 搜索引擎的信息搜索部分就是一种爬虫

---

<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->

### 爬虫的对象和目标是什么？

- 爬虫的对象按照数据来源可以分为 **对软件的爬虫** 和 **对网页的爬虫**。

- 对软件的爬虫主要是对一些手机端 APP 的数据进行爬取，而对网页的爬虫则是对浏览器中的网页进行爬取。

- 爬虫的目标是获取对应的大规模的数据。

---

<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->


### 爬虫需要遵守什么样的规则？

- 任何技术在使用的时候都会伴随安全问题，这是不可避免的。

- 所以互联网相关组织制定了一些关于爬虫的规则，使得这些技术能够最大程度上为我们服务。

- - -

<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->

- 爬虫相关的违法案例一般是 **爬取了不能够爬取的东西** 或者  **使用了爬虫作为信息收集工具进行不正当的信息公开**。

- - -

<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->

- 所以，我们需要遵守以下几点规则：
1. 对于个人隐私信息不应该爬取。
2. 不能够频繁访问一个网站。
3. 某些信息可以收集，但是传播不可以。

---

<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->

### robots.txt 协议需要遵守吗？
- robots.txt 最初是写给搜索引擎爬虫的指引文件。

- 一般情况下，使用代码编写的类似与人类行为的爬虫是不用遵守该协议的。

- - -

<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->


- 但是，满足下列某一条件一定要遵守。

1. 爬取数据用于商业用途
2. 非人类行为频率爬取数据
3. 工程化大型的爬虫项目

---

<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->

### 爬虫面对的困难
- 由于爬虫技术逐渐开始在大学生之间普及，但大学生对于爬虫的规则和技术的操控程度不成熟，导致他们的爬虫经常失控。

- 所以，稍微正规一点的网站都会设计一些常见的反爬手段来阻止简单的爬虫，这些手段称为 **“反爬虫手段”**。


---

<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->

### JSpider 的定位
- JSpider 是服务于爬虫分析部分的快速爬虫库。

- 本身的优点是依附于服务器，可以直接抓包，直接分析执行 js 代码，可以关联 DOM 等优秀的特性，使得它能够快速经由服务器进行爬虫代码的编写，并得到初步的数据。

- - -

<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->

- 对于初学者来说，**没有什么比直接写几行代码就可以爬取上百次据更能体会爬虫的作用**，JSpider 也是基于这一目的制作的。

- 对于编写项目级的爬虫也可以提供准确，快速的判断，减少项目编写的判断难度，提高开发速度。

---

<!-- .slide: data-background-video="https://cdn.jsdelivr.net/gh/KonghaYao/notuse/ppt/video.mp4" data-background-opacity="0.2"-->

### 爬虫编写者需要干的事情
1. 推断网站的数据来源和方式
2. 获取需要爬取的 URL
3. 使用 JSpider 批量请求 URL
4. 使用 JSpider 处理请求数据
5. 使用 JSpider 下载数据即可
